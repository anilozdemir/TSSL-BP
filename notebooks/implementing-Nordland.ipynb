{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Nordland Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import os\n",
    "import torch\n",
    "from network_parser import parse\n",
    "from datasets import loadMNIST, loadCIFAR10, loadFashionMNIST, loadNMNIST_Spiking \n",
    "import logging\n",
    "import cnns\n",
    "import functions.loss_f as loss_f\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import time\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from torch.nn.utils import clip_grad_value_\n",
    "import global_v as glv\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as P\n",
    "import yaml\n",
    "\n",
    "max_accuracy = 0\n",
    "min_loss = 1000\n",
    "\n",
    "from tqdm import tqdm, trange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## works locally only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../../../ActiveAI/pyRC/') # local only! \n",
    "import pyRC.datasets.nordland as Nordland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "File = '../Networks/Nordland_CNN.yaml'\n",
    "with open(File) as file:\n",
    "    params = yaml.full_load(file)\n",
    "    \n",
    "params['Network']['data_path'] = '../' + params['Network']['data_path'] # add relative dir path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nBatch       = params['Network']['batch_size']\n",
    "train_loader = Nordland.get(mode = 'summer', Labels = 'VPR', nImages = 100, nBatch = nBatch, shuffle = False, width=64, height=32)\n",
    "test_loaderS = Nordland.get(mode = 'summer', Labels = 'VPR', nImages = 100, nBatch = nBatch, shuffle = True , width=64, height=32)\n",
    "test_loaderF = Nordland.get(mode = 'fall'  , Labels = 'VPR', nImages = 100, nBatch = nBatch, shuffle = True , width=64, height=32)\n",
    "test_loaderW = Nordland.get(mode = 'winter', Labels = 'VPR', nImages = 100, nBatch = nBatch, shuffle = True , width=64, height=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 64])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.dataset[0][0].unsqueeze(0).shape # trick to add a dimension "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected device:  cuda\n"
     ]
    }
   ],
   "source": [
    "dtype = torch.float32\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"selected device: \", device)\n",
    "\n",
    "glv.init(dtype, device, params['Network']['n_steps'], params['Network']['tau_s'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = params['Network']['n_steps']\n",
    "n_class = params['Network']['n_class']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network Structure:\n",
      "conv_1\n",
      "[1, 32, 64]\n",
      "[15, 28, 60]\n",
      "[15, 1, 5, 5, 1]\n",
      "-----------------------------------------\n",
      "pooling_1\n",
      "[15, 28, 60]\n",
      "[15, 14, 30]\n",
      "[1, 1, 2, 2, 1]\n",
      "-----------------------------------------\n",
      "conv_2\n",
      "[15, 14, 30]\n",
      "[40, 10, 26]\n",
      "[40, 15, 5, 5, 1]\n",
      "-----------------------------------------\n",
      "pooling_2\n",
      "[40, 10, 26]\n",
      "[40, 5, 13]\n",
      "[1, 1, 2, 2, 1]\n",
      "-----------------------------------------\n",
      "linear\n",
      "FC_1\n",
      "[40, 5, 13]\n",
      "[300, 1, 1]\n",
      "[300, 640]\n",
      "-----------------------------------------\n",
      "linear\n",
      "output\n",
      "[300, 1, 1]\n",
      "[100, 1, 1]\n",
      "[100, 300]\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anil/.local/lib/python3.8/site-packages/torch/nn/modules/container.py:434: UserWarning: Setting attributes on ParameterList is not supported.\n",
      "  warnings.warn(\"Setting attributes on ParameterList is not supported.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (my_parameters): ParameterList(\n",
       "      (0): Parameter containing: [torch.cuda.FloatTensor of size 15x1x5x5x1 (GPU 0)]\n",
       "      (1): Parameter containing: [torch.cuda.FloatTensor of size 40x15x5x5x1 (GPU 0)]\n",
       "      (2): Parameter containing: [torch.cuda.FloatTensor of size 300x640 (GPU 0)]\n",
       "      (3): Parameter containing: [torch.cuda.FloatTensor of size 100x300 (GPU 0)]\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = cnns.Network(params['Network'], params['Layers'], list(train_loader.dataset[0][0].unsqueeze(0).shape)).to(device)\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1, 32, 64]) torch.Size([5, 1])\n",
      "torch.Size([5, 1, 28, 28, 5]) torch.Size([5, 100, 1, 1, 5])\n"
     ]
    }
   ],
   "source": [
    "x, label = next(iter(train_loader))\n",
    "x = x.unsqueeze(1)\n",
    "label = label.unsqueeze(1)\n",
    "print(x.shape, label.shape)\n",
    "targets = torch.zeros((label.shape[0], n_class, 1, 1, n_steps), dtype=dtype).to(device) \n",
    "if len(x.shape) < 5:\n",
    "    x = x.unsqueeze_(-1).repeat(1, 1, 1, 1, n_steps)\n",
    "X=x[:,:,:28,:28].to(device).type(dtype)\n",
    "print(X.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = net(X,0,True)\n",
    "spike_counts = torch.sum(outputs, dim=4).squeeze_(-1).squeeze_(-1).detach().cpu().numpy()\n",
    "predicted = np.argmax(spike_counts, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> before tensor([[[[[0, 1, 1, 1, 1]]]]], device='cuda:0')\n",
      ">> after tensor([[[[0.0000, 0.3333, 0.5556, 0.7037, 0.8025]]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "if n_steps >= 10:\n",
    "    desired_spikes = torch.tensor([0, 1, 0, 1, 0, 1, 0, 1, 0, 1]).repeat(int(n_steps/10))\n",
    "else:\n",
    "    desired_spikes = torch.tensor([0, 1, 1, 1, 1]).repeat(int(n_steps/5))\n",
    "desired_spikes = desired_spikes.view(1, 1, 1, 1, n_steps).to(device)\n",
    "print('>> before',desired_spikes)\n",
    "desired_spikes = loss_f.psp(desired_spikes, params['Network']).view(1, 1, 1, n_steps)\n",
    "print('>> after',desired_spikes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network Config\n",
    "network_config = params['Network']\n",
    "n_steps        = network_config['n_steps']\n",
    "n_class        = network_config['n_class']\n",
    "batch_size     = network_config['batch_size']\n",
    "# Training Functions\n",
    "err  = loss_f.SpikeLoss(network_config).to(device)\n",
    "opti = torch.optim.AdamW(net.get_parameters(), lr=network_config['lr'], betas=(0.9, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = 0\n",
    "correct = 0\n",
    "total = 0\n",
    "total_accuracy = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "accuracy so far:0: 100%|██████████| 100/100 [00:50<00:00,  1.99it/s]\n",
      "accuracy so far:0.6885: 100%|██████████| 100/100 [00:49<00:00,  2.00it/s]\n",
      "accuracy so far:0.7564: 100%|██████████| 100/100 [00:49<00:00,  2.01it/s]\n",
      "accuracy so far:0.8048666666666666: 100%|██████████| 100/100 [00:46<00:00,  2.13it/s]\n",
      "accuracy so far:0.844075: 100%|██████████| 100/100 [00:49<00:00,  2.01it/s]\n",
      "accuracy so far:0.8703: 100%|██████████| 100/100 [00:50<00:00,  1.97it/s]\n",
      "accuracy so far:0.8908666666666667: 100%|██████████| 100/100 [00:49<00:00,  2.03it/s]\n",
      "accuracy so far:0.9059: 100%|██████████| 100/100 [00:49<00:00,  2.03it/s]\n",
      "accuracy so far:0.9174625: 100%|██████████| 100/100 [00:49<00:00,  2.04it/s]\n",
      "accuracy so far:0.9265222222222222: 100%|██████████| 100/100 [00:48<00:00,  2.06it/s]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    for _ in tqdm(range(100), desc='accuracy so far:' + str(total_accuracy)):\n",
    "        start_time = time.time()\n",
    "        for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "            targets = torch.zeros((labels.shape[0], n_class, 1, 1, n_steps), dtype=dtype).to(device) \n",
    "            \n",
    "            # begin offline\n",
    "            # this is the case for each item in the for loop, can be done offline, functionally, to speed up!\n",
    "            if len(inputs.shape) < 5: \n",
    "                inputs = inputs.unsqueeze(1).unsqueeze_(-1).repeat(1, 1, 1, 1, n_steps)\n",
    "                inputs = inputs[:,:,:28,:28,:]\n",
    "                \n",
    "            labels = labels.to(device)\n",
    "            inputs = inputs.to(device)\n",
    "            inputs.type(dtype)\n",
    "            # end offline \n",
    "            \n",
    "            outputs = net.forward(inputs, epoch, True)\n",
    "            \n",
    "            # begin function\n",
    "            # seems systematic enough, can be done in a function\n",
    "            if network_config['loss'] == \"count\":\n",
    "                # set target signal\n",
    "                desired_count = network_config['desired_count']\n",
    "                undesired_count = network_config['undesired_count']\n",
    "                targets = torch.ones((outputs.shape[0], outputs.shape[1], 1, 1), dtype=dtype).to(device) * undesired_count\n",
    "                for i in range(len(labels)):\n",
    "                    targets[i, labels[i], ...] = desired_count\n",
    "                loss = err.spike_count(outputs, targets, network_config, layers_config[list(layers_config.keys())[-1]])\n",
    "            elif network_config['loss'] == \"kernel\":\n",
    "                targets.zero_()\n",
    "                for i in range(len(labels)):\n",
    "                    targets[i, labels[i], ...] = desired_spikes\n",
    "                loss = err.spike_kernel(outputs, targets, network_config)\n",
    "            elif network_config['loss'] == \"softmax\":\n",
    "                # set target signal\n",
    "                loss = err.spike_soft_max(outputs, labels)\n",
    "            else:\n",
    "                raise Exception('Unrecognized loss function.')\n",
    "            # end function\n",
    "        \n",
    "            opti.zero_grad()\n",
    "            loss.backward()\n",
    "            clip_grad_norm_(net.get_parameters(), 1) # what's this for?\n",
    "            opti.step()\n",
    "            net.weight_clipper()\n",
    "            \n",
    "            # begin argmax \n",
    "            # PyTorch has argmax function, re-write this and clean up squeezes!\n",
    "            spike_counts = torch.sum(outputs, dim=4).squeeze_(-1).squeeze_(-1).detach().cpu().numpy()\n",
    "            predicted = np.argmax(spike_counts, axis=1)\n",
    "            # end argmax\n",
    "            \n",
    "            # It is not efficient to return to item at each epoch, do we need that?\n",
    "            # Don't think when using W&B at least.\n",
    "            train_loss += torch.sum(loss).item()\n",
    "            labels = labels.cpu().numpy()\n",
    "            total += len(labels)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        total_accuracy = correct / total\n",
    "        total_loss = train_loss / total\n",
    "    end_time = time.time() - start_time\n",
    "#     print('>> result for one set of epochs: {:.3}, time it takes {:.2}s'.format(total_accuracy, end_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93375"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.56\n",
      "0.08\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for tests in [test_loaderS, test_loaderF, test_loaderW]: # test for summer, fall, winter\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        for batch_idx, (inputs, labels) in enumerate(tests):\n",
    "            targets = torch.zeros((labels.shape[0], n_class, 1, 1, n_steps), dtype=dtype).to(device) \n",
    "            if len(inputs.shape) < 5: \n",
    "                inputs = inputs.unsqueeze(1).unsqueeze_(-1).repeat(1, 1, 1, 1, n_steps)\n",
    "                inputs = inputs[:,:,:28,:28,:]\n",
    "            labels = labels.to(device)\n",
    "            inputs = inputs.to(device)\n",
    "            inputs.type(dtype)\n",
    "            outputs = net.forward(inputs, epoch, False)\n",
    "            spike_counts = torch.sum(outputs, dim=4).squeeze_(-1).squeeze_(-1).detach().cpu().numpy()\n",
    "            predicted = np.argmax(spike_counts, axis=1)\n",
    "            labels = labels.cpu().numpy()\n",
    "            total += len(labels)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total_accuracy = correct / total\n",
    "        print(total_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
