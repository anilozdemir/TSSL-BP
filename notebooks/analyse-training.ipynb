{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import os\n",
    "import torch\n",
    "from network_parser import parse\n",
    "from datasets import loadMNIST, loadCIFAR10, loadFashionMNIST, loadNMNIST_Spiking \n",
    "import logging\n",
    "import cnns\n",
    "# from utils import learningStats\n",
    "# from utils import aboutCudaDevices\n",
    "# from utils import EarlyStopping\n",
    "import functions.loss_f as loss_f\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "# import pycuda.driver as cuda\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from torch.nn.utils import clip_grad_value_\n",
    "import global_v as glv\n",
    "\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "\n",
    "# Anil adds\n",
    "import matplotlib\n",
    "matplotlib.use('Agg') \n",
    "import yaml\n",
    "\n",
    "\n",
    "max_accuracy = 0\n",
    "min_loss = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "File = '../Networks/MNIST_CNN.yaml'\n",
    "with open(File) as file:\n",
    "    params = yaml.full_load(file)\n",
    "    \n",
    "params['Network']['data_path'] = '../' + params['Network']['data_path'] # add relative dir path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected device:  cuda\n",
      "loading MNIST\n",
      "what is the problem\n",
      "Network Structure:\n",
      "conv_1\n",
      "[1, 28, 28]\n",
      "[15, 24, 24]\n",
      "[15, 1, 5, 5, 1]\n",
      "-----------------------------------------\n",
      "pooling_1\n",
      "[15, 24, 24]\n",
      "[15, 12, 12]\n",
      "[1, 1, 2, 2, 1]\n",
      "-----------------------------------------\n",
      "conv_2\n",
      "[15, 12, 12]\n",
      "[40, 8, 8]\n",
      "[40, 15, 5, 5, 1]\n",
      "-----------------------------------------\n",
      "pooling_2\n",
      "[40, 8, 8]\n",
      "[40, 4, 4]\n",
      "[1, 1, 2, 2, 1]\n",
      "-----------------------------------------\n",
      "linear\n",
      "FC_1\n",
      "[40, 4, 4]\n",
      "[300, 1, 1]\n",
      "[300, 640]\n",
      "-----------------------------------------\n",
      "linear\n",
      "output\n",
      "[300, 1, 1]\n",
      "[10, 1, 1]\n",
      "[10, 300]\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anil/.local/lib/python3.8/site-packages/torch/nn/modules/container.py:434: UserWarning: Setting attributes on ParameterList is not supported.\n",
      "  warnings.warn(\"Setting attributes on ParameterList is not supported.\")\n"
     ]
    }
   ],
   "source": [
    "dtype = torch.float32\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"selected device: \", device)\n",
    "\n",
    "glv.init(dtype, device, params['Network']['n_steps'], params['Network']['tau_s'] )\n",
    "data_path = os.path.expanduser(params['Network']['data_path'])\n",
    "train_loader, test_loader = loadMNIST.get_mnist(data_path, params['Network'])\n",
    "\n",
    "net = cnns.Network(params['Network'], params['Layers'], list(train_loader.dataset[0][0].shape)).to(device)\n",
    "error = loss_f.SpikeLoss(params['Network']).to(device)\n",
    "optimizer = torch.optim.AdamW(net.get_parameters(), lr=params['Network']['lr'], betas=(0.9, 0.999))\n",
    "\n",
    "best_acc = 0; best_epoch = 0\n",
    "\n",
    "l_states = None\n",
    "early_stopping =None\n",
    "\n",
    "# for e in range(params['Network']['epochs']):\n",
    "#     train(net, train_loader, optimizer, e, l_states, params['Network'], params['Layers'], error)\n",
    "#     test(net, test_loader, e, l_states, params['Network'], params['Layers'], early_stopping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment without Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = params['Network']['n_steps']\n",
    "n_class = params['Network']['n_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (my_parameters): ParameterList(\n",
       "      (0): Parameter containing: [torch.cuda.FloatTensor of size 15x1x5x5x1 (GPU 0)]\n",
       "      (1): Parameter containing: [torch.cuda.FloatTensor of size 40x15x5x5x1 (GPU 0)]\n",
       "      (2): Parameter containing: [torch.cuda.FloatTensor of size 300x640 (GPU 0)]\n",
       "      (3): Parameter containing: [torch.cuda.FloatTensor of size 10x300 (GPU 0)]\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([50, 1, 28, 28, 5]), torch.Size([50, 10, 1, 1, 5]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, label = next(iter(train_loader))\n",
    "x.shape, label.shape\n",
    "targets = torch.zeros((label.shape[0], n_class, 1, 1, n_steps), dtype=dtype).to(device) \n",
    "if len(x.shape) < 5:\n",
    "    x = x.unsqueeze_(-1).repeat(1, 1, 1, 1, n_steps)\n",
    "x.shape, targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = net(x.to(device).type(dtype),0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.5000, 0.2500],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.5000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]], device='cuda:0',\n",
       "       grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.reshape(50,10,5)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desired Spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "if n_steps >= 10:\n",
    "    desired_spikes = torch.tensor([0, 1, 0, 1, 0, 1, 0, 1, 0, 1]).repeat(int(n_steps/10))\n",
    "else:\n",
    "    desired_spikes = torch.tensor([0, 1, 1, 1, 1]).repeat(int(n_steps/5))\n",
    "desired_spikes = desired_spikes.view(1, 1, 1, 1, n_steps).to(device)\n",
    "desired_spikes = loss_f.psp(desired_spikes, params['Network']).view(1, 1, 1, n_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.0000, 0.5000, 0.7500, 0.8750, 0.9375]]]], device='cuda:0')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desired_spikes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training (code below does not work atm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-af2d8141dd18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trainloader' is not defined"
     ]
    }
   ],
   "source": [
    "global max_accuracy\n",
    "global min_loss\n",
    "train_loss = 0\n",
    "correct = 0\n",
    "total = 0\n",
    "n_steps = params['Network']['n_steps']\n",
    "n_class = params['Network']['n_class']\n",
    "batch_size = params['Network']['batch_size']\n",
    "\n",
    "\n",
    "for batch_idx, (inputs, labels) in enumerate(trainloader):\n",
    "    start_time = datetime.now()\n",
    "    targets = torch.zeros((labels.shape[0], n_class, 1, 1, n_steps), dtype=dtype).to(device) \n",
    "    if len(inputs.shape) < 5:\n",
    "        inputs = inputs.unsqueeze_(-1).repeat(1, 1, 1, 1, n_steps)\n",
    "    labels = labels.to(device)\n",
    "    inputs = inputs.to(device)\n",
    "    inputs.type(dtype)\n",
    "    outputs = network.forward(inputs, epoch, True)\n",
    "    if network_config['loss'] == \"count\":\n",
    "        # set target signal\n",
    "        desired_count = network_config['desired_count']\n",
    "        undesired_count = network_config['undesired_count']\n",
    "        targets = torch.ones((outputs.shape[0], outputs.shape[1], 1, 1), dtype=dtype).to(device) * undesired_count\n",
    "        for i in range(len(labels)):\n",
    "            targets[i, labels[i], ...] = desired_count\n",
    "        loss = err.spike_count(outputs, targets, network_config, layers_config[list(layers_config.keys())[-1]])\n",
    "    elif network_config['loss'] == \"kernel\":\n",
    "        targets.zero_()\n",
    "        for i in range(len(labels)):\n",
    "            targets[i, labels[i], ...] = desired_spikes\n",
    "        loss = err.spike_kernel(outputs, targets, network_config)\n",
    "    elif network_config['loss'] == \"softmax\":\n",
    "        # set target signal\n",
    "        loss = err.spike_soft_max(outputs, labels)\n",
    "    else:\n",
    "        raise Exception('Unrecognized loss function.')\n",
    "    opti.zero_grad()\n",
    "    loss.backward()\n",
    "    clip_grad_norm_(network.get_parameters(), 1)\n",
    "    opti.step()\n",
    "    network.weight_clipper()\n",
    "    spike_counts = torch.sum(outputs, dim=4).squeeze_(-1).squeeze_(-1).detach().cpu().numpy()\n",
    "    predicted = np.argmax(spike_counts, axis=1)\n",
    "    train_loss += torch.sum(loss).item()\n",
    "    labels = labels.cpu().numpy()\n",
    "    total += len(labels)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "\n",
    "total_accuracy = correct / total\n",
    "total_loss = train_loss / total\n",
    "if total_accuracy > max_accuracy:\n",
    "    max_accuracy = total_accuracy\n",
    "if min_loss > total_loss:\n",
    "    min_loss = total_loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
