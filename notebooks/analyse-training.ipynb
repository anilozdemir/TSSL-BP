{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import os\n",
    "import torch\n",
    "from network_parser import parse\n",
    "from datasets import loadMNIST, loadCIFAR10, loadFashionMNIST, loadNMNIST_Spiking \n",
    "import logging\n",
    "import cnns\n",
    "# from utils import learningStats\n",
    "# from utils import aboutCudaDevices\n",
    "# from utils import EarlyStopping\n",
    "import functions.loss_f as loss_f\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import time\n",
    "# import pycuda.driver as cuda\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from torch.nn.utils import clip_grad_value_\n",
    "import global_v as glv\n",
    "\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "\n",
    "# Anil adds\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as P\n",
    "import yaml\n",
    "\n",
    "\n",
    "max_accuracy = 0\n",
    "min_loss = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "File = '../Networks/MNIST_CNN.yaml'\n",
    "with open(File) as file:\n",
    "    params = yaml.full_load(file)\n",
    "    \n",
    "params['Network']['data_path'] = '../' + params['Network']['data_path'] # add relative dir path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected device:  cuda\n",
      "loading MNIST\n",
      "Network Structure:\n",
      "conv_1\n",
      "[1, 28, 28]\n",
      "[15, 24, 24]\n",
      "[15, 1, 5, 5, 1]\n",
      "-----------------------------------------\n",
      "pooling_1\n",
      "[15, 24, 24]\n",
      "[15, 12, 12]\n",
      "[1, 1, 2, 2, 1]\n",
      "-----------------------------------------\n",
      "conv_2\n",
      "[15, 12, 12]\n",
      "[40, 8, 8]\n",
      "[40, 15, 5, 5, 1]\n",
      "-----------------------------------------\n",
      "pooling_2\n",
      "[40, 8, 8]\n",
      "[40, 4, 4]\n",
      "[1, 1, 2, 2, 1]\n",
      "-----------------------------------------\n",
      "linear\n",
      "FC_1\n",
      "[40, 4, 4]\n",
      "[300, 1, 1]\n",
      "[300, 640]\n",
      "-----------------------------------------\n",
      "linear\n",
      "output\n",
      "[300, 1, 1]\n",
      "[10, 1, 1]\n",
      "[10, 300]\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anil/.local/lib/python3.8/site-packages/torch/nn/modules/container.py:434: UserWarning: Setting attributes on ParameterList is not supported.\n",
      "  warnings.warn(\"Setting attributes on ParameterList is not supported.\")\n"
     ]
    }
   ],
   "source": [
    "dtype = torch.float32\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"selected device: \", device)\n",
    "\n",
    "glv.init(dtype, device, params['Network']['n_steps'], params['Network']['tau_s'] )\n",
    "data_path = os.path.expanduser(params['Network']['data_path'])\n",
    "train_loader, test_loader = loadMNIST.get_mnist(data_path, params['Network'])\n",
    "\n",
    "net = cnns.Network(params['Network'], params['Layers'], list(train_loader.dataset[0][0].shape)).to(device)\n",
    "error = loss_f.SpikeLoss(params['Network']).to(device)\n",
    "optimizer = torch.optim.AdamW(net.get_parameters(), lr=params['Network']['lr'], betas=(0.9, 0.999))\n",
    "\n",
    "best_acc = 0; best_epoch = 0\n",
    "\n",
    "l_states = None\n",
    "early_stopping =None\n",
    "\n",
    "# for e in range(params['Network']['epochs']):\n",
    "#     train(net, train_loader, optimizer, e, l_states, params['Network'], params['Layers'], error)\n",
    "#     test(net, test_loader, e, l_states, params['Network'], params['Layers'], early_stopping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment without Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = params['Network']['n_steps']\n",
    "n_class = params['Network']['n_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (my_parameters): ParameterList(\n",
       "      (0): Parameter containing: [torch.cuda.FloatTensor of size 15x1x5x5x1 (GPU 0)]\n",
       "      (1): Parameter containing: [torch.cuda.FloatTensor of size 40x15x5x5x1 (GPU 0)]\n",
       "      (2): Parameter containing: [torch.cuda.FloatTensor of size 300x640 (GPU 0)]\n",
       "      (3): Parameter containing: [torch.cuda.FloatTensor of size 10x300 (GPU 0)]\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([50, 1, 28, 28, 5]), torch.Size([50, 10, 1, 1, 5]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, label = next(iter(train_loader))\n",
    "x.shape, label.shape\n",
    "targets = torch.zeros((label.shape[0], n_class, 1, 1, n_steps), dtype=dtype).to(device) \n",
    "if len(x.shape) < 5:\n",
    "    x = x.unsqueeze_(-1).repeat(1, 1, 1, 1, n_steps)\n",
    "x.shape, targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = net(x.to(device).type(dtype),0,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]], device='cuda:0', grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.reshape(50,10,5)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desired Spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> before tensor([[[[[0, 1, 1, 1, 1]]]]], device='cuda:0')\n",
      ">> after tensor([[[[0.0000, 0.3333, 0.5556, 0.7037, 0.8025]]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "if n_steps >= 10:\n",
    "    desired_spikes = torch.tensor([0, 1, 0, 1, 0, 1, 0, 1, 0, 1]).repeat(int(n_steps/10))\n",
    "else:\n",
    "    desired_spikes = torch.tensor([0, 1, 1, 1, 1]).repeat(int(n_steps/5))\n",
    "desired_spikes = desired_spikes.view(1, 1, 1, 1, n_steps).to(device)\n",
    "print('>> before',desired_spikes)\n",
    "desired_spikes = loss_f.psp(desired_spikes, params['Network']).view(1, 1, 1, n_steps)\n",
    "print('>> after',desired_spikes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading MNIST\n"
     ]
    }
   ],
   "source": [
    "# global max_accuracy\n",
    "# global min_loss\n",
    "# Datasets\n",
    "data_path = os.path.expanduser(params['Network']['data_path'])\n",
    "trainloader, testloader = loadMNIST.get_mnist(data_path, params['Network'])\n",
    "# Network Config\n",
    "network_config = params['Network']\n",
    "n_steps        = network_config['n_steps']\n",
    "n_class        = network_config['n_class']\n",
    "batch_size     = network_config['batch_size']\n",
    "# Training Functions\n",
    "err  = loss_f.SpikeLoss(network_config).to(device)\n",
    "opti = torch.optim.AdamW(net.get_parameters(), lr=network_config['lr'], betas=(0.9, 0.999))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train for one epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = 0\n",
    "correct = 0\n",
    "total = 0\n",
    "epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> result for one epoch: 0.99, time it takes 0.059s\n"
     ]
    }
   ],
   "source": [
    "for batch_idx, (inputs, labels) in enumerate(trainloader):\n",
    "    start_time = time.time()\n",
    "    targets = torch.zeros((labels.shape[0], n_class, 1, 1, n_steps), dtype=dtype).to(device) \n",
    "    \n",
    "    # begin offline\n",
    "    # this is the case for each item in the for loop, can be done offline, functionally, to speed up!\n",
    "    if len(inputs.shape) < 5: \n",
    "        inputs = inputs.unsqueeze_(-1).repeat(1, 1, 1, 1, n_steps)\n",
    "    labels = labels.to(device)\n",
    "    inputs = inputs.to(device)\n",
    "    inputs.type(dtype)\n",
    "    # end offline \n",
    "    \n",
    "    outputs = net.forward(inputs, epoch, True)\n",
    "    \n",
    "    # begin function\n",
    "    # seems systematic enough, can be done in a function\n",
    "    if network_config['loss'] == \"count\":\n",
    "        # set target signal\n",
    "        desired_count = network_config['desired_count']\n",
    "        undesired_count = network_config['undesired_count']\n",
    "        targets = torch.ones((outputs.shape[0], outputs.shape[1], 1, 1), dtype=dtype).to(device) * undesired_count\n",
    "        for i in range(len(labels)):\n",
    "            targets[i, labels[i], ...] = desired_count\n",
    "        loss = err.spike_count(outputs, targets, network_config, layers_config[list(layers_config.keys())[-1]])\n",
    "    elif network_config['loss'] == \"kernel\":\n",
    "        targets.zero_()\n",
    "        for i in range(len(labels)):\n",
    "            targets[i, labels[i], ...] = desired_spikes\n",
    "        loss = err.spike_kernel(outputs, targets, network_config)\n",
    "    elif network_config['loss'] == \"softmax\":\n",
    "        # set target signal\n",
    "        loss = err.spike_soft_max(outputs, labels)\n",
    "    else:\n",
    "        raise Exception('Unrecognized loss function.')\n",
    "    # end function\n",
    "\n",
    "    opti.zero_grad()\n",
    "    loss.backward()\n",
    "    clip_grad_norm_(net.get_parameters(), 1) # what's this for?\n",
    "    opti.step()\n",
    "    net.weight_clipper()\n",
    "    \n",
    "    # begin argmax \n",
    "    # PyTorch has argmax function, re-write this and clean up squeezes!\n",
    "    spike_counts = torch.sum(outputs, dim=4).squeeze_(-1).squeeze_(-1).detach().cpu().numpy()\n",
    "    predicted = np.argmax(spike_counts, axis=1)\n",
    "    # end argmax\n",
    "    \n",
    "    # It is not efficient to return to item at each epoch, do we need that?\n",
    "    # Don't think when using W&B at least.\n",
    "    train_loss += torch.sum(loss).item()\n",
    "    labels = labels.cpu().numpy()\n",
    "    total += len(labels)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "\n",
    "total_accuracy = correct / total\n",
    "total_loss = train_loss / total\n",
    "end_time = time.time() - start_time\n",
    "print('>> result for one epoch: {:.3}, time it takes {:.2}s'.format(total_accuracy, end_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPRESSIVE RESULTS\n",
    "> result for one epoch: 0.987, time it takes 0.071s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
